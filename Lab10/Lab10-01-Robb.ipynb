{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10: Recommender System\n",
    "\n",
    "In this assignment, we will study how to do user-based collaborative filtering and item-based collaborative filtering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset\n",
    "\n",
    "In this assignment, we will use MovieLens-100K dataset. It includes about 100,000 ratings from 1000 users on 1700 movies.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 1664)\n",
      "(943, 1664)\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "# 1. load data\n",
    "user_ratings_train = pd.read_csv('./ml-100k/u1.base',\n",
    "                            sep='\\t',names=['user_id','movie_id','rating'], usecols=[0,1,2])\n",
    "\n",
    "user_ratings_test = pd.read_csv('./ml-100k/u1.test',\n",
    "                            sep='\\t',names=['user_id','movie_id','rating'], usecols=[0,1,2])\n",
    "\n",
    "movie_info =  pd.read_csv('./ml-100k/u.item', \n",
    "                          sep='|', names=['movie_id','title'], usecols=[0,1],\n",
    "                          encoding=\"ISO-8859-1\")\n",
    "\n",
    "user_ratings_train = pd.merge(movie_info, user_ratings_train)\n",
    "user_ratings_test = pd.merge(movie_info, user_ratings_test)\n",
    "\n",
    "# 2. get the rating matrix. Each row is a user, and each column is a movie.\n",
    "user_ratings_train = user_ratings_train.pivot_table(index=['user_id'],\n",
    "                                        columns=['title'],\n",
    "                                        values='rating')\n",
    "\n",
    "user_ratings_test = user_ratings_test.pivot_table(index=['user_id'],\n",
    "                                        columns=['title'],\n",
    "                                        values='rating')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "user_ratings_train = user_ratings_train.reindex(\n",
    "                            index=user_ratings_train.index.union(user_ratings_test.index), \n",
    "                            columns=user_ratings_train.columns.union(user_ratings_test.columns) )\n",
    "\n",
    "user_ratings_test = user_ratings_test.reindex(\n",
    "                            index=user_ratings_train.index.union(user_ratings_test.index), \n",
    "                            columns=user_ratings_train.columns.union(user_ratings_test.columns) )\n",
    "\n",
    "print(user_ratings_train.shape)\n",
    "print(user_ratings_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. User-based CF\n",
    "\n",
    "* Use pearson correlation to get the similarity between different users.\n",
    "* Based on the obtained similarity score, predict the ratings. You can use 5 nearest neighbors or 10 nearest neighbors.\n",
    "* Compute MAE for the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00  2.32208120e-02  1.32786679e-02 ...  6.16507063e-02\n",
      "  -3.06075887e-02  5.98564252e-02]\n",
      " [ 2.32208120e-02  1.00000000e+00  9.51733735e-03 ...  5.34428840e-03\n",
      "   2.50789352e-02  4.37874936e-02]\n",
      " [ 1.32786679e-02  9.51733735e-03  1.00000000e+00 ...  3.58078305e-02\n",
      "   3.83776757e-02  5.34075010e-03]\n",
      " ...\n",
      " [ 6.16507063e-02  5.34428840e-03  3.58078305e-02 ...  1.00000000e+00\n",
      "  -1.85501504e-02  6.66444773e-04]\n",
      " [-3.06075887e-02  2.50789352e-02  3.83776757e-02 ... -1.85501504e-02\n",
      "   1.00000000e+00  4.11337777e-02]\n",
      " [ 5.98564252e-02  4.37874936e-02  5.34075010e-03 ...  6.66444773e-04\n",
      "   4.11337777e-02  1.00000000e+00]]\n",
      "\n",
      "\n",
      "MAE for testing set: 0.8316716024705649\n"
     ]
    }
   ],
   "source": [
    "# your code\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#fills Nan with average\n",
    "user_ratings_train['avg'] = user_ratings_train.mean(axis=1)\n",
    "user_ratings_train_noNan = user_ratings_train.T.fillna(user_ratings_train['avg'], axis=0).T\n",
    "\n",
    "#pearson correlation\n",
    "pearson_sim_train = 1-pairwise_distances(user_ratings_train_noNan, metric=\"correlation\")\n",
    "print(pearson_sim_train)\n",
    "print(\"\\n\")\n",
    "\n",
    "#5 nearest neighbors \n",
    "train_model = NearestNeighbors(n_neighbors=10)\n",
    "train_model.fit(pearson_sim_train)\n",
    "neighbors_distance, neighbors_ind = train_model.kneighbors()\n",
    "\n",
    "#reseting index\n",
    "neighbors_ind += 1\n",
    "\n",
    "predictions = []\n",
    "actual = []\n",
    "\n",
    "#predict the ratings\n",
    "for user_id, row in user_ratings_test.iterrows():\n",
    "    for movie, rating in row.iteritems():\n",
    "        if not pd.isnull(rating):\n",
    "            predicted_rating = 0\n",
    "            sum_of_sim = 0\n",
    "            for x in range(0,10):\n",
    "                ngbh_id = neighbors_ind[user_id-1][x]\n",
    "                nghb_rating = user_ratings_train.loc[ngbh_id,movie]\n",
    "                if not pd.isnull(nghb_rating):\n",
    "                    nghb_distance = neighbors_distance[user_id-1][x]\n",
    "                    sum_of_sim += nghb_distance\n",
    "                    predicted_rating += nghb_distance*(nghb_rating-user_ratings_train.loc[ngbh_id, 'avg'])\n",
    "            if (sum_of_sim != 0):\n",
    "                predicted_rating = predicted_rating/sum_of_sim\n",
    "                predicted_rating += user_ratings_train.loc[user_id, 'avg']\n",
    "                predictions.append(predicted_rating)\n",
    "                actual.append(rating)\n",
    "\n",
    "#10 KNN has smaller MAE\n",
    "mae = mean_absolute_error(predictions, actual)\n",
    "print(\"MAE for testing set: \" + str(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Item-based CF\n",
    "* Use cosine similarity to get the similarity between different items.\n",
    "* Based on the obtained similarity score, predict the ratings. You can use 5 nearest neighbors or 10 nearest neighbors.\n",
    "* Compute MAE for the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.99940449 0.99317483 ... 0.99942103 0.99975181 0.99215062]\n",
      " [0.99940449 1.         0.99316242 ... 0.9992226  0.99965259 0.99230413]\n",
      " [0.99317483 0.99316242 1.         ... 0.99316242 0.99350757 0.98762425]\n",
      " ...\n",
      " [0.99942103 0.9992226  0.99316242 ... 1.         0.99965259 0.99196888]\n",
      " [0.99975181 0.99965259 0.99350757 ... 0.99965259 1.         0.99222378]\n",
      " [0.99215062 0.99230413 0.98762425 ... 0.99196888 0.99222378 1.        ]]\n",
      "\n",
      "\n",
      "MAE for testing set: 1.0371091280012175\n"
     ]
    }
   ],
   "source": [
    "# your code\n",
    "item_ratings_train = user_ratings_train.T\n",
    "item_ratings_test = user_ratings_test.T\n",
    "\n",
    "#fill Nans with row avg\n",
    "item_ratings_train['avg'] = item_ratings_train.mean(axis=1)\n",
    "item_ratings_train_noNan = item_ratings_train.T.fillna(item_ratings_train['avg'], axis=0).T\n",
    "\n",
    "#drop rows with missing data  \n",
    "dropped_rows = item_ratings_train_noNan[item_ratings_train_noNan.isna().any(axis=1)]\n",
    "item_ratings_train_noNan = item_ratings_train_noNan.drop(dropped_rows.index)\n",
    "item_ratings_test = item_ratings_test.drop(dropped_rows.index)\n",
    "\n",
    "#cosine similarity\n",
    "cosine_sim_train = 1-pairwise_distances(item_ratings_train_noNan, metric=\"cosine\")\n",
    "print(pearson_sim_train)\n",
    "print(\"\\n\")\n",
    "\n",
    "#5 nearest neighbors \n",
    "train_model = NearestNeighbors(n_neighbors=10)\n",
    "train_model.fit(cosine_sim_train)\n",
    "neighbors_distance, neighbors_ind = train_model.kneighbors()\n",
    "\n",
    "#reseting index\n",
    "neighbors_ind += 1\n",
    "\n",
    "predictions = []\n",
    "actual = []\n",
    "\n",
    "#predicting ratings\n",
    "for movie_id, row in item_ratings_test.iterrows():\n",
    "    item_id = item_ratings_test.index.get_loc(movie_id)\n",
    "    for user, rating in row.iteritems():\n",
    "        if not pd.isnull(rating):\n",
    "            predicted_rating = 0\n",
    "            sum_of_sim = 0\n",
    "            for x in range(0,10):\n",
    "                ngbh_id = neighbors_ind[item_id][x]\n",
    "                nghb_rating = item_ratings_train.iloc[ngbh_id].loc[user]\n",
    "                if not pd.isnull(nghb_rating):\n",
    "                    nghb_distance = neighbors_distance[item_id][x]\n",
    "                    sum_of_sim += nghb_distance\n",
    "                    predicted_rating += nghb_distance*(nghb_rating)\n",
    "            if (sum_of_sim != 0):\n",
    "                predicted_rating = predicted_rating/sum_of_sim\n",
    "                predictions.append(predicted_rating)\n",
    "                actual.append(rating)\n",
    "\n",
    "#10 KNN has smaller MAE\n",
    "mae = mean_absolute_error(predictions, actual)\n",
    "print(\"MAE for testing set: \" + str(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
