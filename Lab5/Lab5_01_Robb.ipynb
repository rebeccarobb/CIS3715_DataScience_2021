{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will learn the Logistic Regression model.\n",
    "\n",
    "First, please study the given example, which uses the logistic regression model for the breast cancer classification task. In this example, you will learn how to preprocess data, how to train the model, and how to evaluate the model.\n",
    "\n",
    "Based on the given example, your task is to use the logistic regression model to predict the presence of heart disease.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load the breast cancer data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use the [breast cancer](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer) dataset in sklearn. It is a binary classification dataset. Each sample has 30 numerical features, which can be found in [7.1.7](https://scikit-learn.org/stable/datasets/toy_dataset.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#samples: 569, #features: 30\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from random import shuffle\n",
    "import random\n",
    "random.seed(123)\n",
    "\n",
    "X, y = datasets.load_breast_cancer(return_X_y=True)\n",
    "print(\"#samples: {}, #features: {}\".format(X.shape[0], X.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Split the data into two subsets and normalize the features of samples\n",
    "\n",
    "Here, we use 69 samples as the testing set and use the remained samples to train the logistic regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_val: 500, test: 69\n"
     ]
    }
   ],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, \n",
    "                                                            test_size=0.12, \n",
    "                                                            random_state=0)\n",
    "print(\"train_val: {}, test: {}\".format(X_train_val.shape[0], X_test.shape[0]))\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_val = normalizer.fit_transform(X_train_val)\n",
    "X_test = normalizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Train the logistic regression model and select the hyperparameter with cross-validation\n",
    "\n",
    "Here, we use the following logistic regression model to do cancer classification. \n",
    "\n",
    "\\begin{equation}\n",
    "\t\\min_{\\mathbf{w}} \\sum_{i=1}^{n}\\{\\log(1+\\exp(\\mathbf{w}^T\\mathbf{x}_i))-y_i\\mathbf{w}^T\\mathbf{x}_i \\} + \\lambda\\|\\mathbf{w}\\|_2^2\n",
    "\\end{equation}\n",
    "\n",
    "We need to learn the model parameter $\\mathbf{w}$. However, with different hyperparameters $\\lambda$, we can get different model parameter $\\mathbf{w}$, resulting in different prediction performance. Here, we use the 5-fold cross-validation to select the hyperparameter $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[380 468 145   2 282 103 148 312 130 411 168 204 113 132 418 270 351 157\n",
      "  451 339 288 277 354  48 318 303 314 234  95 304 271 434 173 357 495 133\n",
      "  431  39 490 310 317 471  23 426 224 286  20 365 255 216 405  79 228 445\n",
      "  189 184 243 358 276 218 488  60 438 159 167 349  89 121 333  51   9 482\n",
      "  152 416 379 306 111 185 340 489 475  93  84 376 291 158 250 323 406 460\n",
      "   50 433 372  66 108 465  71 298 369 437]\n",
      " [211  11 110 142  28  59 163  38  24 205 440 140 177 252 235 245 242  25\n",
      "   21 217 160 231  77 151  54 345 280 257 456 308 331  58 360 179 464 388\n",
      "  129 285 347  56 387 169  36 138 319 296 246 122  33 127 109 363 183 196\n",
      "  422  86 400 297 346 116  63  88 477 144 112 362 399 334  62 353 146 373\n",
      "   27  76 260 150 210 195 290  82 154 432 320 361  75  17  94 238 143 469\n",
      "   67 225 391 106  15  97  46  49 192 226]\n",
      " [114 302 356  91  80 107 329 209 384 409  13 176 299 483 295 491 332 292\n",
      "  153 202 268   1 417 313 375 128 352  57 408 254 382 390 377 328 213 182\n",
      "   65   7 315 101 187 126 123 394 201 251 494 239 383 367 237  34 307 141\n",
      "  403 344 162  43 118 498  99 392 102 258 100  41 281 364 492 448 164 104\n",
      "  124 259 355 458 484 115 309 338  53 381 442  70 284 263 419 166 441 481\n",
      "  335 219 155 294 230 378 476 232 480  31]\n",
      " [343 197 301  85  61 264 446 273 455 188 199 452  74 443 423 395 265  29\n",
      "   40 120 190  73 348 415 474 337  12 178 212 402 478 412 241 454 165  14\n",
      "  206 325 279 398 366 462   4 221 421 389 181 413  32 316 493 473 215 324\n",
      "  425 139 424 385 131 453  98 470  68   5 459 236 466 227 487  78  90 439\n",
      "  278 119 368 322 253 147 435  30 397 256 272 207 117 180 430 186 321  45\n",
      "  300  96   8 401 450 198 233 370  37 200]\n",
      " [283 479 171  87 134 336 249  42 371  92 427 386  16 261 191 214 342 266\n",
      "  248 467 457 407 326 275 350 222 262 330 444 203   6 472 414 289 269 327\n",
      "  311 420 105 247 410 267 175 156 496  18 428 240 135 244 293 220 149  10\n",
      "  404  64  72 341  47  22  52 229 374 161   3  35 193 305 449 497 396 223\n",
      "  463   0  83 125 359 485 486 172  69  81 499 436 174 170 287 274 194  19\n",
      "  447 461 429  55 136 208 393  44 137  26]]\n",
      "reg_coeff: 10.0, acc: 0.970\n",
      "reg_coeff: 2.0, acc: 0.978\n",
      "reg_coeff: 1.0, acc: 0.972\n",
      "reg_coeff: 0.2, acc: 0.968\n",
      "reg_coeff: 0.1, acc: 0.968\n"
     ]
    }
   ],
   "source": [
    "# here we use 5-fold cross-validation\n",
    "folds = 5\n",
    "\n",
    "# get the number of samples in the training and validation set\n",
    "num_train_val = X_train_val.shape[0] \n",
    "\n",
    "# shuffle the index of samples in the train_val set\n",
    "index_of_samples = np.arange(num_train_val) \n",
    "shuffle(index_of_samples)\n",
    "\n",
    "# split the index of the train_valid set into 5 folds\n",
    "index_of_folds = index_of_samples.reshape(folds, -1)\n",
    "print(index_of_folds)\n",
    "\n",
    "# potential hyperparameters. \n",
    "#These hyperparameters are just used for illustration. \n",
    "#You should try more hyperparameters to get a good model.\n",
    "#The hyperparameters must be nonnegative!\n",
    "regularization_coefficient = [0.1, 0.5, 1.0, 5.0, 10.0]\n",
    "\n",
    "best_acc = 0.0\n",
    "best_reg = 0.0\n",
    "\n",
    "for reg in regularization_coefficient:\n",
    "    \n",
    "    # 5-fold cross-validation\n",
    "    sum_acc = 0.0\n",
    "    for fold in range(folds):\n",
    "        \n",
    "        index_of_folds_temp = index_of_folds.copy()\n",
    "        \n",
    "        valid_index = index_of_folds_temp[fold,:].reshape(-1) #get the index of the validation set\n",
    "        train_index = np.delete(index_of_folds_temp, fold, 0).reshape(-1) #get the index of the training set\n",
    "        \n",
    "        # training set\n",
    "        X_train = X_train_val[train_index]\n",
    "        y_train = y_train_val[train_index]\n",
    "        \n",
    "        # validation set\n",
    "        X_valid = X_train_val[valid_index]\n",
    "        y_valid = y_train_val[valid_index]\n",
    "                \n",
    "        # build the model with different hyperparameters\n",
    "        clf = LogisticRegression(penalty='l2', C=reg, solver='lbfgs')\n",
    "        \n",
    "        #train the model with the training set\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        y_valid_pred = clf.predict(X_valid)\n",
    "        acc = accuracy_score(y_valid, y_valid_pred)\n",
    "        \n",
    "        sum_acc += acc\n",
    "    \n",
    "    cur_acc = sum_acc / folds\n",
    "    \n",
    "    print(\"reg_coeff: {}, acc: {:.3f}\".format(1.0/reg, cur_acc))\n",
    "    \n",
    "    # store the best hyperparameter\n",
    "    if cur_acc > best_acc:\n",
    "        best_acc = cur_acc\n",
    "        best_reg = reg\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Evaluate the learned model\n",
    "\n",
    "After getting the best hyperparameter $\\lambda$, we retrain the model with the train_val set. Then, we evaluate this  model on the testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 1.000, recall: 1.000, precision: 1.000, f1: 1.000,\n"
     ]
    }
   ],
   "source": [
    "# retrain the model\n",
    "clf = LogisticRegression(penalty='l2', C=best_reg, solver='lbfgs')\n",
    "clf.fit(X_train_val, y_train_val)\n",
    "\n",
    "# evaluate the model on the testing set\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "print(\"accuracy: {:.3f}, recall: {:.3f}, precision: {:.3f}, f1: {:.3f},\".format(acc, recall, precision, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Task\n",
    "\n",
    "Here, we use the [heart disease](./heart.csv) dataset. Each sample has the following feature: \n",
    "\n",
    "* age\n",
    "* sex\n",
    "* chest pain type (4 values)\n",
    "* resting blood pressure\n",
    "* serum cholestoral in mg/dl\n",
    "* fasting blood sugar > 120 mg/dl\n",
    "* resting electrocardiographic results (values 0,1,2)\n",
    "* maximum heart rate achieved\n",
    "* exercise induced angina\n",
    "* oldpeak = ST depression induced by exercise relative to rest\n",
    "* the slope of the peak exercise ST segment\n",
    "* number of major vessels (0-3) colored by flourosopy\n",
    "* thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
    "\n",
    "The last column refers to the presence of heart disease in the patient.\n",
    "\n",
    "The task is to predict whether a person has the heart disease. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Preprocess the raw data\n",
    "\n",
    "* Check whether there are missing values\n",
    "* Check whether theare are cateogrical features\n",
    "* Check whether this dataset is balanced or not (use the bar plot to visualize the number of positive and negative samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n",
      "\n",
      " Result: No missing values\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n",
      "None\n",
      "\n",
      " Result: No categorical values\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Heart Disease Patients(1) and Not Heart Diseased(0)\n",
      "\n",
      " Result: patient data is balanced\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from random import shuffle\n",
    "import random\n",
    "random.seed(123)\n",
    "\n",
    "\n",
    "#import data frame\n",
    "df = pd.read_csv('heart.csv')\n",
    "\n",
    "#check missing values\n",
    "print(df.isnull().sum()) \n",
    "print(\"\\n Result: No missing values\\n\")\n",
    "\n",
    "#check categorical values\n",
    "print(df.info())\n",
    "print(\"\\n Result: No categorical values\\n\")\n",
    "\n",
    "#check to see if df is balanced\n",
    "df['target'].value_counts().plot(kind = 'bar', figsize = (1, 3))\n",
    "plt.title('Patient Target:')\n",
    "plt.show\n",
    "plt.show(block=False)\n",
    "print(' Heart Disease Patients(1) and Not Heart Diseased(0)')\n",
    "print(\"\\n Result: patient data is balanced\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Split the data into two subsets and normalize the features of samples\n",
    "\n",
    "* Split the dataset into the train_val set and testing set. \n",
    "* Normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_val: 260, test: 43\n"
     ]
    }
   ],
   "source": [
    "#splitting the data into training and testing sets\n",
    "\n",
    "X = df.drop('target', axis=1).values\n",
    "y = df['target'].values\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.14, random_state=0)\n",
    "\n",
    "print(\"train_val: {}, test: {}\".format(X_train_val.shape[0], X_test.shape[0]))\n",
    "\n",
    "#normalizing features\n",
    "normalizer = StandardScaler()\n",
    "X_train_val = normalizer.fit_transform(X_train_val)\n",
    "X_test = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Train the logistic regression model and select the hyperparameter with cross-validation\n",
    "\n",
    "\\begin{equation}\n",
    "\t\\min_{\\mathbf{w}} \\sum_{i=1}^{n}\\{\\log(1+\\exp(\\mathbf{w}^T\\mathbf{x}_i))-y_i\\mathbf{w}^T\\mathbf{x}_i \\} + \\lambda\\|\\mathbf{w}\\|_2^2\n",
    "\\end{equation}\n",
    "\n",
    "* Use the 10-fold cross-validation to select the hyperparameter $\\lambda$.\n",
    "* Search $\\lambda$ from $\\{10^{-5}, 10^{-4}, 10^{-3}, 10^{-2}, 10^{-1}, 1, 10, 20, 50, 100\\}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[130 138 236 246 201 145 122 213 242 185 231 150  22  10 180 115  81 202\n",
      "    2 230  58 135 256  40  87  32]\n",
      " [142  59 103 181 175 111  88 125  77  62 237 149 171  97  15 198  29 247\n",
      "  254  98 223 104  94  45 177 127]\n",
      " [153 108  35  76 208 119 193  71 169 241 227 147 151  95  38  17 229 196\n",
      "   90 183 133 117 101 168  42 197]\n",
      " [238 217 214  12  67  82 124   4 228   3 126 235 118  56  11 120   9 232\n",
      "  259 140  55 157 211  51  24 249]\n",
      " [ 57 116 148 221  70 144  85 146  19 114 222 110 251 121 128  63  27  54\n",
      "  200 212 159  36  39  37   5  86]\n",
      " [131  79  48  13 143 100 257 205  16 210 191  43 107  68 137  44  21 155\n",
      "  226 164  61  53 253 239 161 192]\n",
      " [ 46 245 206 166 225 178  28 179   1  60 112  78 163  73  84 174 252 170\n",
      "   30 209 132 243 158  23 105  64]\n",
      " [ 33 203  65  14  92 219  31  69 240 250 182  34  25 233  93 218 207 172\n",
      "  160 195   7 186 255   6  99  41]\n",
      " [139 141 167  72 123 199 109  91 234  52  49  18 173 162 102  50 136 190\n",
      "  152 187  26 220 113  83 156  47]\n",
      " [184  96  20  75 165 244 194 129 248 204   0 258 176  80  89  74 154   8\n",
      "  224 106 216  66 189 188 215 134]]\n",
      "reg_coeff: 99999.99999999999, acc: 0.554\n",
      "reg_coeff: 10000.0, acc: 0.554\n",
      "reg_coeff: 1000.0, acc: 0.704\n",
      "reg_coeff: 100.0, acc: 0.831\n",
      "reg_coeff: 10.0, acc: 0.831\n",
      "reg_coeff: 1.0, acc: 0.831\n",
      "reg_coeff: 0.1, acc: 0.831\n",
      "reg_coeff: 0.05, acc: 0.831\n",
      "reg_coeff: 0.02, acc: 0.831\n",
      "reg_coeff: 0.01, acc: 0.831\n"
     ]
    }
   ],
   "source": [
    "#10 folds\n",
    "folds = 10 \n",
    "\n",
    "# get the number of samples in the training and validation set\n",
    "num_train_val = X_train_val.shape[0] \n",
    "\n",
    "# shuffle the index of samples in the train_val set\n",
    "index_of_samples = np.arange(num_train_val) \n",
    "shuffle(index_of_samples)\n",
    "\n",
    "# split the index of the train_valid set into 5 folds\n",
    "index_of_folds = index_of_samples.reshape(folds, -1)\n",
    "print(index_of_folds)\n",
    "\n",
    "# potential hyperparameters used for illustration. \n",
    "regularization_coefficient = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 20, 50, 100]\n",
    "\n",
    "best_acc = 0.0\n",
    "best_reg = 0.0\n",
    "\n",
    "for reg in regularization_coefficient:\n",
    "    sum_acc = 0.0\n",
    "    for fold in range(folds):\n",
    "        \n",
    "        index_of_folds_temp = index_of_folds.copy()\n",
    "        \n",
    "        valid_index = index_of_folds_temp[fold,:].reshape(-1) #get the index of the validation set\n",
    "        train_index = np.delete(index_of_folds_temp, fold, 0).reshape(-1) #get the index of the training set\n",
    "        \n",
    "        # training set\n",
    "        X_train = X_train_val[train_index]\n",
    "        y_train = y_train_val[train_index]\n",
    "        \n",
    "        # validation set\n",
    "        X_valid = X_train_val[valid_index]\n",
    "        y_valid = y_train_val[valid_index]\n",
    "                \n",
    "        # build the model with different hyperparameters\n",
    "        clf = LogisticRegression(penalty='l2', C=reg, solver='lbfgs')\n",
    "        \n",
    "        #train the model with the training set\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        y_valid_pred = clf.predict(X_valid)\n",
    "        acc = accuracy_score(y_valid, y_valid_pred)\n",
    "        \n",
    "        sum_acc += acc\n",
    "    \n",
    "    cur_acc = sum_acc / folds\n",
    "    \n",
    "    print(\"reg_coeff: {}, acc: {:.3f}\".format(1.0/reg, cur_acc))\n",
    "    \n",
    "    # store the best hyperparameter\n",
    "    if cur_acc > best_acc:\n",
    "        best_acc = cur_acc\n",
    "        best_reg = reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Evaluate the learned model\n",
    "\n",
    "* Report the prediction accuracy, recall, precision, and F1 score.\n",
    "\n",
    "* Use the bar plot to visulaize the elements of the learned model parameter vector $\\mathbf{w}$. Some elements  have larger absolute values, while the others do not. Try to explain this phenomenon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.791, recall: 0.905, precision: 0.731, f1: 0.809,\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The larger the absolute value the more significant the coefficent is pertaining to having heart disease.For example, chest pain, angina, and thalassemia are very significant and indicates the large possibiltyit correlates to having heart disease where as fasting blood sugar does not which is not a good correlationindicator of having heart disease.\n"
     ]
    }
   ],
   "source": [
    "# retrain the model\n",
    "clf = LogisticRegression(penalty='l2', C=best_reg, solver='lbfgs')\n",
    "clf.fit(X_train_val, y_train_val)\n",
    "\n",
    "# evaluate the model on the testing set\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "print(\"accuracy: {:.3f}, recall: {:.3f}, precision: {:.3f}, f1: {:.3f},\".format(acc, recall, precision, f1))\n",
    "plt.bar(df.columns[:-1], clf.coef_[0], figure=plt.figure(1, [10, 8]))\n",
    "plt.title(\"Learned Elements\")\n",
    "plt.show\n",
    "plt.show(block=False)\n",
    "\n",
    "print(\"The larger the absolute value the more significant the coefficent is pertaining to having heart disease.\" +\n",
    "      \"For example, chest pain, angina, and thalassemia are very significant and indicates the large possibilty\" +\n",
    "      \"it correlates to having heart disease where as fasting blood sugar does not which is not a good correlation\" +\n",
    "      \"indicator of having heart disease.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
