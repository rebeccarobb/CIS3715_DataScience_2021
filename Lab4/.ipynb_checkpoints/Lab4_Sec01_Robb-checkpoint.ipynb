{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will learn the Linear Regression model. \n",
    "\n",
    "First, please study the given example, which uses linear regression for the house price prediction task. In this example, you will learn how to preprocess data, how to train the model, and how to evaluate the model. \n",
    "\n",
    "Based on the given example and Lab Assignment 3, your task is to use the linear regression model to predict the medical cost for the dataset given in Lab Assignment 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Example: Linear Regression for House Price Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we use the house price dataset. It gives the attributes and price of each house. The task is to build a linear regression model to make prediction for the price of the house."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Preprocess the raw data\n",
    "\n",
    "When given a new dataset, we need to deal with the missing values and categorical features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longitude             0\n",
      "latitude              0\n",
      "housing_median_age    0\n",
      "total_rooms           0\n",
      "total_bedrooms        0\n",
      "population            0\n",
      "households            0\n",
      "median_income         0\n",
      "median_house_value    0\n",
      "ocean_proximity       0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      "longitude             20640 non-null float64\n",
      "latitude              20640 non-null float64\n",
      "housing_median_age    20640 non-null int64\n",
      "total_rooms           20640 non-null int64\n",
      "total_bedrooms        20640 non-null float64\n",
      "population            20640 non-null int64\n",
      "households            20640 non-null int64\n",
      "median_income         20640 non-null float64\n",
      "median_house_value    20640 non-null int64\n",
      "ocean_proximity       20640 non-null int64\n",
      "dtypes: float64(4), int64(6)\n",
      "memory usage: 1.6 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df = pd.read_csv('housing.csv')\n",
    "\n",
    "# 0. fill in missing values\n",
    "mean_val = df['total_bedrooms'].mean()\n",
    "df['total_bedrooms'] = df['total_bedrooms'].fillna(mean_val)\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# 1. convert categorical features to numerical values\n",
    "labelencoder = LabelEncoder()\n",
    "df['ocean_proximity'] = labelencoder.fit_transform(df['ocean_proximity'])\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Split the preprocessed dataset into training set and testing set\n",
    "\n",
    "For the supervised learning, we need to split the dataset into the training set and test set. The training set is used to learn model parameters and the testing set is used to evaluate the learned model. \n",
    "\n",
    "Note that the testing set is NOT allowed to be used in the training phase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16512, 9)\n",
      "(4128, 9)\n"
     ]
    }
   ],
   "source": [
    "# 2. split samples\n",
    "house_fea = df.drop('median_house_value', axis=1).values\n",
    "house_price = df['median_house_value'].values\n",
    "house_price = house_price / np.max(house_price)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(house_fea,\n",
    "                                                 house_price,\n",
    "                                                 test_size=0.2,\n",
    "                                                 random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "\n",
    "# normalize features\n",
    "normalizer = StandardScaler()\n",
    "X_train = normalizer.fit_transform(X_train)\n",
    "X_test = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Train the linear regression model \n",
    "\n",
    "$\\min_{w}\\frac{1}{n}\\|y-X\\mathbf{w}\\|_2^2$\n",
    "\n",
    "\n",
    "\n",
    "Here, we use the training set to learn the model parameter $\\mathbf{w}=(w_0, w_1, w_2, \\cdots, w_d)$. \n",
    "\n",
    "Then, we compute MAE, MSE, and RMSE to see how well the learned model fit the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias is 0.41438855869860675\n",
      "coefficients  is [-0.17170955 -0.18189176  0.02984855 -0.0353864   0.09753502 -0.08776816\n",
      "  0.03520256  0.15428789 -0.00090304]\n",
      "prediction for training set:\n",
      "MAE is: 0.10125365457873205\n",
      "MSE is: 0.0192437559440504\n",
      "RMSE is: 0.13872186541439818\n"
     ]
    }
   ],
   "source": [
    "#3. train the model\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "print(\"bias is \"+str(lr.intercept_))\n",
    "print(\"coefficients  is \"+str(lr.coef_))\n",
    "\n",
    "y_train_pred = lr.predict(X_train)\n",
    "\n",
    "mae = mean_absolute_error(y_train_pred,y_train)\n",
    "mse = mean_squared_error(y_train_pred,y_train)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('prediction for training set:')\n",
    "print('MAE is: {}'.format(mae))\n",
    "print('MSE is: {}'.format(mse))\n",
    "print('RMSE is: {}'.format(rmse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Evaluate the linear regression model\n",
    "\n",
    "After obtaining the model parameter $\\mathbf{w}=(w_0, w_1, w_2, \\cdots, w_d)$, the linear regression model is determined. Then, we need to evaluate this model to see how well this model generaizes on the testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction for testing set:\n",
      "MAE is: 0.1036935483109797\n",
      "MSE is: 0.02022001958450324\n",
      "RMSE is: 0.14219711524677017\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#4. evaluate the model\n",
    "y_test_pred = lr.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test_pred,y_test)\n",
    "mse = mean_squared_error(y_test_pred,y_test)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('prediction for testing set:')\n",
    "print('MAE is: {}'.format(mae))\n",
    "print('MSE is: {}'.format(mse))\n",
    "print('RMSE is: {}'.format(rmse))\n",
    "\n",
    "\n",
    "labels = ['House1', 'House2', 'House3', 'House4', 'House5']\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, y_test[0:5], width, label='ground truth')\n",
    "rects2 = ax.bar(x + width/2, y_test_pred[0:5], width, label='prediction')\n",
    "\n",
    "ax.set_ylabel('Price')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Task: Linear Regression for Medical Cost Prediction\n",
    "\n",
    "Following the given example, build a linear regression model for [the insurance dataset](./insurance.csv) to predict the medical cost.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Preprocess the raw data\n",
    "\n",
    "Based on your Lab Assignment 3, deal with the missing values and categorical features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      age     sex     bmi  children smoker     region      charges\n",
      "0      19  female  27.900         0    yes  southwest  16884.92400\n",
      "1      18    male  33.770         1     no  southeast   1725.55230\n",
      "2      28    male  33.000         3     no  southeast   4449.46200\n",
      "3      33    male  22.705         0     no  northwest  21984.47061\n",
      "4      32    male  28.880         0     no  northwest   3866.85520\n",
      "...   ...     ...     ...       ...    ...        ...          ...\n",
      "1333   50    male  30.970         3     no  northwest  10600.54830\n",
      "1334   18  female  31.920         0     no  northeast   2205.98080\n",
      "1335   18  female  36.850         0     no  southeast   1629.83350\n",
      "1336   21  female  25.800         0     no  southwest   2007.94500\n",
      "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
      "\n",
      "[1338 rows x 7 columns] \n",
      "\n",
      "age         0\n",
      "sex         0\n",
      "bmi         0\n",
      "children    0\n",
      "smoker      0\n",
      "region      0\n",
      "charges     0\n",
      "dtype: int64 \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1338 non-null   int64  \n",
      " 1   sex       1338 non-null   object \n",
      " 2   bmi       1338 non-null   float64\n",
      " 3   children  1338 non-null   int64  \n",
      " 4   smoker    1338 non-null   object \n",
      " 5   region    1338 non-null   object \n",
      " 6   charges   1338 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 73.3+ KB\n",
      "None \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1338 non-null   int64  \n",
      " 1   sex       1338 non-null   int64  \n",
      " 2   bmi       1338 non-null   float64\n",
      " 3   children  1338 non-null   int64  \n",
      " 4   smoker    1338 non-null   int64  \n",
      " 5   region    1338 non-null   int64  \n",
      " 6   charges   1338 non-null   float64\n",
      "dtypes: float64(2), int64(5)\n",
      "memory usage: 73.3 KB\n",
      "None \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#include libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import the data frame\n",
    "df = pd.read_csv('insurance.csv')\n",
    "print(df, \"\\n\")\n",
    "\n",
    "#check missing values\n",
    "print(df.isnull().sum(), \"\\n\")\n",
    "\n",
    "#convert catgorical values into numerical \n",
    "print(df.info(), \"\\n\")\n",
    "labelencoder = LabelEncoder()\n",
    "df['sex'] = labelencoder.fit_transform(df['sex'])\n",
    "df['smoker'] = labelencoder.fit_transform(df['smoker'])\n",
    "df['region'] = labelencoder.fit_transform(df['region'])\n",
    "\n",
    "print(df.info(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Split the preprocessed dataset into training set and testing set\n",
    "\n",
    "Use 80% of samples as the training set and 20% of samples as the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1070, 6)\n",
      "(268, 6)\n"
     ]
    }
   ],
   "source": [
    "# split samples\n",
    "insurance_fea = df.drop('charges', axis=1).values\n",
    "insurance_price = df['charges'].values\n",
    "insurance_price = insurance_price / np.max(insurance_price)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(insurance_fea,\n",
    "                                                 insurance_price,\n",
    "                                                 test_size=0.2,\n",
    "                                                 random_state=42)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "\n",
    "# normalize features\n",
    "normalizer = StandardScaler()\n",
    "X_train = normalizer.fit_transform(X_train)\n",
    "X_test = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Train the linear regression model \n",
    "\n",
    "Use the Linear regression model to do prediction\n",
    "\n",
    "$\\min_{w}\\frac{1}{n}\\|y-X\\mathbf{w}\\|_2^2$\n",
    "\n",
    "Please output the learned model parameter $\\mathbf{w}$ and see how the learned model fit the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias is 0.20928336460705027\n",
      "coefficients  is [ 5.67051024e-02 -1.47293258e-04  3.18064131e-02  8.10191467e-03\n",
      "  1.49867951e-01 -4.74182139e-03]\n",
      "prediction for training set:\n",
      "MAE is: 0.06599864797091512\n",
      "MSE is: 0.00916737434945697\n",
      "RMSE is: 0.09574640645714579\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "print(\"bias is \"+str(lr.intercept_))\n",
    "print(\"coefficients  is \"+str(lr.coef_))\n",
    "\n",
    "y_train_pred = lr.predict(X_train)\n",
    "\n",
    "mae = mean_absolute_error(y_train_pred,y_train)\n",
    "mse = mean_squared_error(y_train_pred,y_train)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('prediction for training set:')\n",
    "print('MAE is: {}'.format(mae))\n",
    "print('MSE is: {}'.format(mse))\n",
    "print('RMSE is: {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Evaluate the linear regression model\n",
    "\n",
    "\n",
    "Evaluate the learned model to see how well this model generaizes on the testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction for testing set:\n",
      "MAE is: 0.06564969107169771\n",
      "MSE is: 0.008270951713078178\n",
      "RMSE is: 0.09094477287386109\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#evaluate the model\n",
    "y_test_pred = lr.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test_pred,y_test)\n",
    "mse = mean_squared_error(y_test_pred,y_test)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('prediction for testing set:')\n",
    "print('MAE is: {}'.format(mae))\n",
    "print('MSE is: {}'.format(mse))\n",
    "print('RMSE is: {}'.format(rmse))\n",
    "\n",
    "\n",
    "labels = ['Person1', 'Person2', 'Person3', 'Person4', 'Person5']\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, y_test[0:5], width, label='ground truth')\n",
    "rects2 = ax.bar(x + width/2, y_test_pred[0:5], width, label='prediction')\n",
    "\n",
    "ax.set_ylabel('Price')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Use the ridge regression model to do prediction\n",
    "\n",
    "$\\min_{w}\\frac{1}{n}\\|y-Xw\\|_2^2 + \\lambda \\|w\\|_2^2$\n",
    "\n",
    "* 1.5.1 Compare its performance on the testing set with that of the standard linear regression model $\\min_{w}\\frac{1}{n}\\|y-Xw\\|_2^2$\n",
    "\n",
    "* 1.5.2 Use different $\\lambda$ to see how it affects the performance of the ridge regression  model on the testing set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.1\n",
      "\n",
      "bias is 0.20928336460705027\n",
      "coefficients is [ 5.66477072e-02 -1.36912304e-04  3.17814658e-02  8.09963575e-03\n",
      "  1.49724329e-01 -4.73350751e-03]\n",
      "prediction for testing set\n",
      "MAE is: 0.06567262940074653\n",
      "MSE is: 0.0082725766695483\n",
      "RMSE is 0.09095370618918341\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comparing the preformance of the ridege regression model (1.5.1) and the linear training model (1.4):\n",
      "the numerical values of the errors are extremly close\n"
     ]
    }
   ],
   "source": [
    "print('1.5.1\\n')\n",
    "\n",
    "rr = Ridge(alpha = 1)\n",
    "rr.fit(X_train,y_train)\n",
    "\n",
    "print(\"bias is \" +str(rr.intercept_))\n",
    "print(\"coefficients is \" +str(rr.coef_))\n",
    "\n",
    "y_test_pred = rr.predict(X_test)\n",
    " \n",
    "mae = mean_absolute_error(y_test_pred,y_test)\n",
    "mse = mean_squared_error(y_test_pred,y_test)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('prediction for testing set')\n",
    "print('MAE is: {}'.format(mae))\n",
    "print('MSE is: {}'.format(mse))\n",
    "print('RMSE is {}'.format(rmse))\n",
    "\n",
    "\n",
    "labels = ['Person1', 'Person2', 'Person3', 'Person4', 'Person5']\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, y_test[0:5], width, label='ground truth')\n",
    "rects2 = ax.bar(x + width/2, y_test_pred[0:5], width, label='prediction')\n",
    "\n",
    "ax.set_ylabel('Price')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "plt.show() \n",
    "\n",
    "print('comparing the preformance of the ridege regression model (1.5.1) and the linear training model (1.4):')\n",
    "print('the numerical values of the errors are extremly close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.2\n",
      "\n",
      "𝜆 = 0.1\n",
      "bias is 0.20928336460705027\n",
      "coefficients are [ 5.66993576e-02 -1.46253412e-04  3.18039167e-02  8.10168706e-03\n",
      "  1.49853576e-01 -4.74098902e-03]\n",
      "prediction for testing set\n",
      "MAE is: 0.06565198712488936\n",
      "MSE is: 0.008271112026766067\n",
      "RMSE is 0.09094565424893081\n",
      "\n",
      "\n",
      "𝜆 = 1.0\n",
      "bias is 0.20928336460705027\n",
      "coefficients are [ 5.66477072e-02 -1.36912304e-04  3.17814658e-02  8.09963575e-03\n",
      "  1.49724329e-01 -4.73350751e-03]\n",
      "prediction for testing set\n",
      "MAE is: 0.06567262940074653\n",
      "MSE is: 0.0082725766695483\n",
      "RMSE is 0.09095370618918341\n",
      "\n",
      "\n",
      "𝜆 = 20.0\n",
      "bias is 0.20928336460705027\n",
      "coefficients are [ 5.55791066e-02  5.31387207e-05  3.13145546e-02  8.05522453e-03\n",
      "  1.47047190e-01 -4.57960785e-03]\n",
      "prediction for testing set\n",
      "MAE is: 0.06613364774215816\n",
      "MSE is: 0.00831230764817267\n",
      "RMSE is 0.09117185776418439\n",
      "\n",
      "\n",
      "𝜆 = 200\n",
      "bias is 0.20928336460705027\n",
      "coefficients are [ 0.04716695  0.00132911  0.02747503  0.00757177  0.12576511 -0.00343135]\n",
      "prediction for testing set\n",
      "MAE is: 0.07174363643409837\n",
      "MSE is: 0.00926530148826035\n",
      "RMSE is 0.0962564360874656\n",
      "\n",
      "\n",
      "𝜆 = 1000\n",
      "bias is 0.2092833646070503\n",
      "coefficients are [ 0.02826016  0.00264647  0.01773202  0.00557093  0.07661135 -0.00134672]\n",
      "prediction for testing set\n",
      "MAE is: 0.09391805281994185\n",
      "MSE is: 0.015797099360113406\n",
      "RMSE is 0.12568651224420785\n",
      "\n",
      "\n",
      "\n",
      "Observation:\n",
      "Using different values for lambda, the performance of the ridge regression model on the testing set shows that\n",
      "the larger the lambda the greater the error. As lambda decreases, the mean squared error decreases.\n"
     ]
    }
   ],
   "source": [
    "print('1.5.2\\n')\n",
    "\n",
    "\n",
    "print('𝜆 = 0.1')\n",
    "rr = Ridge(alpha = 0.1)\n",
    "rr.fit(X_train,y_train)\n",
    "\n",
    "print(\"bias is \" +str(rr.intercept_))\n",
    "print(\"coefficients are \" +str(rr.coef_))\n",
    "\n",
    "y_test_pred = rr.predict(X_test)\n",
    " \n",
    "mae = mean_absolute_error(y_test_pred,y_test)\n",
    "mse = mean_squared_error(y_test_pred,y_test)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('prediction for testing set')\n",
    "print('MAE is: {}'.format(mae))\n",
    "print('MSE is: {}'.format(mse))\n",
    "print('RMSE is {}'.format(rmse))\n",
    "\n",
    "\n",
    "print('\\n\\n𝜆 = 1.0')\n",
    "rr = Ridge(alpha = 1.0)\n",
    "rr.fit(X_train,y_train)\n",
    "\n",
    "print(\"bias is \" +str(rr.intercept_))\n",
    "print(\"coefficients are \" +str(rr.coef_))\n",
    "\n",
    "y_test_pred = rr.predict(X_test)\n",
    " \n",
    "mae = mean_absolute_error(y_test_pred,y_test)\n",
    "mse = mean_squared_error(y_test_pred,y_test)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('prediction for testing set')\n",
    "print('MAE is: {}'.format(mae))\n",
    "print('MSE is: {}'.format(mse))\n",
    "print('RMSE is {}'.format(rmse))\n",
    "\n",
    "\n",
    "print('\\n\\n𝜆 = 20.0')\n",
    "rr = Ridge(alpha = 20)\n",
    "rr.fit(X_train,y_train)\n",
    "\n",
    "print(\"bias is \" +str(rr.intercept_))\n",
    "print(\"coefficients are \" +str(rr.coef_))\n",
    "\n",
    "y_test_pred = rr.predict(X_test)\n",
    " \n",
    "mae = mean_absolute_error(y_test_pred,y_test)\n",
    "mse = mean_squared_error(y_test_pred,y_test)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('prediction for testing set')\n",
    "print('MAE is: {}'.format(mae))\n",
    "print('MSE is: {}'.format(mse))\n",
    "print('RMSE is {}'.format(rmse))\n",
    "\n",
    "\n",
    "\n",
    "print('\\n\\n𝜆 = 200')\n",
    "rr = Ridge(alpha = 200)\n",
    "rr.fit(X_train,y_train)\n",
    "\n",
    "print(\"bias is \" +str(rr.intercept_))\n",
    "print(\"coefficients are \" +str(rr.coef_))\n",
    "\n",
    "y_test_pred = rr.predict(X_test)\n",
    " \n",
    "mae = mean_absolute_error(y_test_pred,y_test)\n",
    "mse = mean_squared_error(y_test_pred,y_test)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('prediction for testing set')\n",
    "print('MAE is: {}'.format(mae))\n",
    "print('MSE is: {}'.format(mse))\n",
    "print('RMSE is {}'.format(rmse))\n",
    "\n",
    "\n",
    "print('\\n\\n𝜆 = 1000')\n",
    "rr = Ridge(alpha = 1000)\n",
    "rr.fit(X_train,y_train)\n",
    "\n",
    "print(\"bias is \" +str(rr.intercept_))\n",
    "print(\"coefficients are \" +str(rr.coef_))\n",
    "\n",
    "y_test_pred = rr.predict(X_test)\n",
    " \n",
    "mae = mean_absolute_error(y_test_pred,y_test)\n",
    "mse = mean_squared_error(y_test_pred,y_test)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('prediction for testing set')\n",
    "print('MAE is: {}'.format(mae))\n",
    "print('MSE is: {}'.format(mse))\n",
    "print('RMSE is {}'.format(rmse))\n",
    "\n",
    "\n",
    "print('\\n\\n\\nObservation:\\n' + \n",
    "      'Using different values for lambda, '+ \n",
    "      'the performance of the ridge regression model on the testing set shows that\\n' +\n",
    "      'the larger the lambda the greater the error. ' + \n",
    "      'As lambda decreases, the mean squared error decreases.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
